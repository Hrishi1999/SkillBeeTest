{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indianfoodclassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python37664bitdevcondadcce82d69a5b45ed87a328c63c049a7d",
      "display_name": "Python 3.7.6 64-bit ('dev': conda)"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "0b1c0c5d6d4cd233e037f1139e2b5d2eb1fe337ed42272ffa4ed68c312149f02"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwM_CmZgZo6k"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#   try:\n",
        "#     # Currently, memory growth needs to be the same across GPUs\n",
        "#     for gpu in gpus:\n",
        "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
        "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "#   except RuntimeError as e:\n",
        "#     # Memory growth must be set before GPUs have been initialized\n",
        "#     print(e)\n",
        "# Uncomment this if you get cuDNN init error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfWFXVxGZ5OF"
      },
      "source": [
        "data_root='C:\\\\Users\\\\hrish\\\\Desktop\\\\ML\\\\Image-Segregation-with-KMeans\\\\op'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W3us5WOaLtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08a6982-64a8-4cb5-ebe5-1e32dd769beb"
      },
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "TRAINING_DATA_DIR = str(data_root)\n",
        "\n",
        "print(TRAINING_DATA_DIR);\n",
        "\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs\n",
        "# rotation_range=20,\n",
        "# width_shift_range=0.2,\n",
        "# height_shift_range=0.2,\n",
        "# shear_range=0.2,\n",
        "# zoom_range=0.2,\n",
        "# horizontal_flip=True,\n",
        "# fill_mode='nearest'\n",
        ")\n",
        "# Uncomment above code to enable Image Augmentation\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"training\",\n",
        "shuffle=True,\n",
        "target_size=IMAGE_SHAPE)\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"validation\",\n",
        "shuffle=True,\n",
        "target_size=IMAGE_SHAPE\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\hrish\\Desktop\\ML\\Image-Segregation-with-KMeans\\op\nFound 700 images belonging to 2 classes.\nFound 175 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEPsbB3uaQO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0252c1e-804c-4672-e001-64edb29dd324"
      },
      "source": [
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "print(\"Image batch shape: \", image_batch_train.shape)\n",
        "print(\"Label batch shape: \", label_batch_train.shape)\n",
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([k.title() for k, v in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape:  (32, 224, 224, 3)\nLabel batch shape:  (32, 2)\n['Document' 'Garbage']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTcRg-wRaVMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963df6e0-4884-4799-ff93-ab59931e1d15"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
        "output_shape=[1280],\n",
        "trainable=False),\n",
        "tf.keras.layers.Dropout(0.4),\n",
        "tf.keras.layers.Dense(512, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(128, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "model.build([None, 224, 224, 3])\n",
        "model.summary()\n",
        "model.compile(\n",
        "optimizer=tf.keras.optimizers.Adam(),\n",
        "loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# # Logistic Regression\n",
        "# model = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(2, kernel_regularizer=tf.keras.regularizers.L1L2(l1=0.0, l2=0.1), activation=tf.nn.softmax)\n",
        "# ])\n",
        "\n",
        "# Custom CNN\n",
        "# model = tf.keras.Sequential([\n",
        "#   tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(224, 224, 3)),\n",
        "#   tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "#   tf.keras.layers.MaxPooling2D(),\n",
        "#   tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "#   tf.keras.layers.MaxPooling2D(),\n",
        "#   tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#   tf.keras.layers.MaxPooling2D(),\n",
        "#   tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#   tf.keras.layers.MaxPooling2D(),\n",
        "#   tf.keras.layers.Flatten(),\n",
        "#   tf.keras.layers.Dense(256, activation='relu'),\n",
        "#   tf.keras.layers.Dense(2, activation='softmax')\n",
        "# ])\n",
        "model.build([None, 224, 224, 3])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nkeras_layer_1 (KerasLayer)   (None, 1280)              2257984   \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1280)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               655872    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 2,979,778\nTrainable params: 721,794\nNon-trainable params: 2,257,984\n_________________________________________________________________\nModel: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nkeras_layer_1 (KerasLayer)   (None, 1280)              2257984   \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1280)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               655872    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 2,979,778\nTrainable params: 721,794\nNon-trainable params: 2,257,984\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOwfg-KxafV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6db6c6-e217-48a8-f3dd-52f550fd8316"
      },
      "source": [
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
        "hist = model.fit(\n",
        "train_generator,\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "steps_per_epoch=steps_per_epoch,\n",
        "validation_data=valid_generator,\n",
        "validation_steps=val_steps_per_epoch).history"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-a5870f06a405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m validation_steps=val_steps_per_epoch).history\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2590\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2592\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2593\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKpoJCO8Wg76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "outputId": "09e6d369-bdec-414d-d032-1ef468f9af4f"
      },
      "source": [
        "epoch_count = range(1, len(hist[\"loss\"]) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, hist[\"loss\"], 'r--')\n",
        "plt.plot(epoch_count, hist[\"val_loss\"], 'b-')\n",
        "plt.legend(['Training Loss', 'Test Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,50])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKWO5y92ah7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982e6721-4372-4086-eafe-74d3c10b79e8"
      },
      "source": [
        "MODEL_PATH = \"model_lg\"\n",
        "tf.saved_model.save(model, MODEL_PATH)\n",
        "assg_model = tf.keras.models.load_model(MODEL_PATH, custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c94tKLLncUdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90bb269-12b0-4815-ce02-200765067754"
      },
      "source": [
        "val_image_batch, val_label_batch = next(iter(valid_generator))\n",
        "true_label_ids = np.argmax(val_label_batch, axis=-1)\n",
        "print(\"Validation batch shape:\", val_image_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joT4nPEpdBFX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "52e406d1-9ffb-46d0-eaa1-9005069bc842"
      },
      "source": [
        "%%time\n",
        "tf_model_predictions = assg_model.predict(val_image_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puDiJ83ydCxO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "31ca7bae-de31-4b2f-c4f3-63cf40ecd089"
      },
      "source": [
        "predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n",
        "predicted_labels = dataset_labels[predicted_ids]\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(val_image_batch[n])\n",
        "  color = \"green\" if predicted_ids[n] == true_label_ids[n] else \"red\"\n",
        "  plt.title(predicted_labels[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "  _ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}